{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e23a5ce-c8a2-4427-875a-cef6af7c83c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 28645 features, but AffinityPropagation is expecting 100 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m new_tweets_tfidf \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(new_tweets_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Predict labels using Affinity Propagation\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m ap_labels \u001b[38;5;241m=\u001b[39m affinity_propagation\u001b[38;5;241m.\u001b[39mpredict(new_tweets_tfidf)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Predict labels using Agglomerative Clustering\u001b[39;00m\n\u001b[0;32m     26\u001b[0m agg_labels \u001b[38;5;241m=\u001b[39m agglomerative_clustering\u001b[38;5;241m.\u001b[39mfit_predict(new_tweets_tfidf\u001b[38;5;241m.\u001b[39mtoarray())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:545\u001b[0m, in \u001b[0;36mAffinityPropagation.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict the closest cluster each sample in X belongs to.\u001b[39;00m\n\u001b[0;32m    532\u001b[0m \n\u001b[0;32m    533\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m    Cluster labels.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    544\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 545\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster_centers_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    548\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredict method is not supported when affinity=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    549\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 28645 features, but AffinityPropagation is expecting 100 features as input."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load your pretrained models and vectorizer\n",
    "with open('affinity_propagation_model.pkl', 'rb') as f:\n",
    "    affinity_propagation = pickle.load(f)\n",
    "\n",
    "with open('agglomerative_clustering_labels.pkl', 'rb') as f:\n",
    "    agglomerative_clustering = pickle.load(f)\n",
    "\n",
    "# Change this line to load the vectorizer instead of the tfidf_matrix\n",
    "with open('vectorizer.pkl', 'rb') as f:  # Load the vectorizer not the matrix\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "# Load your new tweets data\n",
    "new_tweets_df = pd.read_csv('unseen_tweets.csv')\n",
    "\n",
    "# Transform the new tweets using the vectorizer\n",
    "new_tweets_tfidf = vectorizer.transform(new_tweets_df['tweet_text'])\n",
    "\n",
    "# Predict labels using Affinity Propagation\n",
    "ap_labels = affinity_propagation.predict(new_tweets_tfidf)\n",
    "\n",
    "# Predict labels using Agglomerative Clustering\n",
    "agg_labels = agglomerative_clustering.fit_predict(new_tweets_tfidf.toarray())\n",
    "\n",
    "# Store the results in the DataFrame\n",
    "new_tweets_df['ap_labels'] = ap_labels\n",
    "new_tweets_df['agg_labels'] = agg_labels\n",
    "\n",
    "# Save or display the results DataFrame\n",
    "new_tweets_df.to_csv('new_tweets_with_labels.csv', index=False)\n",
    "print(new_tweets_df[['tweet_text', 'ap_labels', 'agg_labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e36194d-4060-4d71-8830-02ffda5d2c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'unseen_tweets.csv' has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Sample tweets\n",
    "# tweets = [\n",
    "#     \"Just finished a great book! 📚 What's everyone else reading?\",\n",
    "#     \"Loving this new café in town! The coffee is amazing! ☕️\",\n",
    "#     \"Can't believe how fast time flies! Where did this year go?\",\n",
    "#     \"Tried a new recipe today and it turned out delicious! 🍽️\",\n",
    "#     \"Excited to hit the gym later today! 💪 Fitness is life!\",\n",
    "#     \"Just had the best day at the beach! 🌊☀️\",\n",
    "#     \"Why does it always rain on the weekends? 🌧️\",\n",
    "#     \"Caught up with an old friend today—so nice to reconnect! 🤗\",\n",
    "#     \"Planning a trip to the mountains next month! 🏔️ Can't wait!\",\n",
    "#     \"Just finished binge-watching a new series. Totally hooked! 🎥\",\n",
    "#     \"Anyone else obsessed with true crime podcasts? 🔍\",\n",
    "#     \"Feeling a bit under the weather today. Hoping for a quick recovery! 🤒\",\n",
    "#     \"A little self-care goes a long way. Treat yourself! 💆‍♀️\",\n",
    "#     \"Can't stop thinking about how amazing last night's concert was! 🎶\",\n",
    "#     \"Coffee, sunshine, and a good book—perfect Saturday! 🌞\",\n",
    "#     \"Just got some new art supplies! Can’t wait to start creating! 🎨\",\n",
    "#     \"Looking forward to the long weekend! Any fun plans? 🥳\",\n",
    "#     \"The sunset tonight was absolutely breathtaking! 🌅\",\n",
    "#     \"Just discovered a great new playlist! 🎧 What are you listening to?\",\n",
    "#     \"Who else loves spontaneous road trips? 🚗✨\",\n",
    "#     \"Trying to eat healthier—any good recipe recommendations? 🥗\",\n",
    "#     \"Just saw a shooting star! 🌠 Wish granted?\",\n",
    "#     \"Had a productive day at work—feeling accomplished! 💼\",\n",
    "#     \"Can't wait for Halloween! 🎃 Any costume ideas?\",\n",
    "#     \"Just got back from the farmers market—so much fresh produce! 🥬\",\n",
    "#     \"Busy week ahead, but I'm ready to tackle it! 📅\",\n",
    "#     \"Why is it so hard to find matching socks? 🧦\",\n",
    "#     \"Just got a new plant for my apartment! 🌿 Any name suggestions?\",\n",
    "#     \"Feeling grateful for the little things in life. 🙏\",\n",
    "#     \"Just completed a challenging puzzle! 🧩 Anyone else like puzzles?\",\n",
    "#     \"I wish weekends lasted longer! 😩\",\n",
    "#     \"The first snowfall feels magical! ❄️\",\n",
    "#     \"Can't wait to see my favorite band perform live again! 🎤\",\n",
    "#     \"Just finished a great workout! Endorphins are flowing! 🏋️‍♀️\",\n",
    "#     \"Tried a new dance class today—so much fun! 💃\",\n",
    "#     \"Who else struggles with Monday motivation? 🙈\",\n",
    "#     \"Just adopted a cute puppy! 🐶 Any training tips?\",\n",
    "#     \"Road trip playlist complete! 🎶 Let's hit the road!\",\n",
    "#     \"Excited to start my new job next week! 🎉\",\n",
    "#     \"What’s your go-to comfort food on a rainy day? 🍲\"\n",
    "# ]\n",
    "\n",
    "# # Create a DataFrame\n",
    "# tweets_df = pd.DataFrame(tweets, columns=[\"tweet_text\"])\n",
    "\n",
    "# # Save the DataFrame to a CSV file\n",
    "# tweets_df.to_csv('unseen_tweets.csv', index=False)\n",
    "\n",
    "# print(\"CSV file 'unseen_tweets.csv' has been created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc1cb2-6062-4540-9236-cd8322543bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
