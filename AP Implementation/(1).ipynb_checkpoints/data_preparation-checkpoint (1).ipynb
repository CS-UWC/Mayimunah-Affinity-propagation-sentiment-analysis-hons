{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "597999fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_preparation\n",
    "# Importing Necessary Libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0640beff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Mayimunah\n",
      "[nltk_data]     Nagayi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mayimunah\n",
      "[nltk_data]     Nagayi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed8aaf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading the CSV files\n",
    "df1 = pd.read_csv('Tweets.csv') #kaggle\n",
    "df2 = pd.read_csv('test.csv')#Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b4bcd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET 1\n",
      "           textID                                               text  \\\n",
      "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
      "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
      "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
      "27479  ed167662a5                         But it was worth it  ****.   \n",
      "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
      "\n",
      "                                           selected_text sentiment  \n",
      "27476                                             d lost  negative  \n",
      "27477                                      , don`t force  negative  \n",
      "27478                          Yay good for both of you.  positive  \n",
      "27479                         But it was worth it  ****.  positive  \n",
      "27480  All this flirting going on - The ATG smiles. Y...   neutral  \n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET 1\")\n",
    "print(df1.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a73c5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET 2\n",
      "     original_index                sid  \\\n",
      "495            8908  twitter-test-8909   \n",
      "496            2517  twitter-test-2518   \n",
      "497            5224  twitter-test-5225   \n",
      "498            2995  twitter-test-2996   \n",
      "499            1825  twitter-test-1826   \n",
      "\n",
      "                                                  text  label label_text  \n",
      "495  Fire broke out in one of the #Palestinian shop...      1    neutral  \n",
      "496  @user Well, I doubt Saakashvili is above rent-...      0   negative  \n",
      "497  @user is it foggy? Foggy and cold in Tipp all ...      0   negative  \n",
      "498  @user really? ðŸ˜¦ Because I'm practicing vegetar...      1    neutral  \n",
      "499  @user @user What trash did you put in that kid...      0   negative  \n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET 2\")\n",
    "print(df2.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c804807e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERGED DATASET\n",
      "    textID                                               text selected_text  \\\n",
      "495    NaN  Fire broke out in one of the #Palestinian shop...           NaN   \n",
      "496    NaN  @user Well, I doubt Saakashvili is above rent-...           NaN   \n",
      "497    NaN  @user is it foggy? Foggy and cold in Tipp all ...           NaN   \n",
      "498    NaN  @user really? ðŸ˜¦ Because I'm practicing vegetar...           NaN   \n",
      "499    NaN  @user @user What trash did you put in that kid...           NaN   \n",
      "\n",
      "    sentiment  original_index                sid  label label_text  \n",
      "495       NaN          8908.0  twitter-test-8909    1.0    neutral  \n",
      "496       NaN          2517.0  twitter-test-2518    0.0   negative  \n",
      "497       NaN          5224.0  twitter-test-5225    0.0   negative  \n",
      "498       NaN          2995.0  twitter-test-2996    1.0    neutral  \n",
      "499       NaN          1825.0  twitter-test-1826    0.0   negative  \n"
     ]
    }
   ],
   "source": [
    "# Merge the two dataframes\n",
    "merged_df = pd.concat([df1, df2])\n",
    "print(\"MERGED DATASET\")\n",
    "print(merged_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "639982c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from the merged dataframe\n",
    "merged_df = merged_df.drop_duplicates(subset='text').reset_index(drop=True)\n",
    "\n",
    "# Select only the 'text' column\n",
    "merged_df = merged_df[['text']]\n",
    "merged_df['text'] = merged_df['text'].astype(str)\n",
    "\n",
    "# Write the merged dataframe to a new CSV file\n",
    "merged_df.to_csv('merged_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3faf4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for text cleaning, tokenization, and normalization\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)  # Removing special characters and punctuation\n",
    "    text = re.sub(r'user', '', text)  # Removing mentions of @user\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word.lower() for word in tokens if word.lower() not in stop_words]  # Removing stopwords and converting to lowercase\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f1152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                          id responded going\n",
      "1                     sooo sad miss san diego\n",
      "2                               boss bullying\n",
      "3                       interview leave alone\n",
      "4    sons couldnt put releases already bought\n",
      "Name: cleaned_text, dtype: object\n",
      "27976    fire broke one palestinian shops occupied jeru...\n",
      "27977                 well doubt saakashvili rentanangymob\n",
      "27978                           foggy foggy cold tipp week\n",
      "27979    really im practicing vegetarianism ive seen li...\n",
      "27980    trash put kids head shame youor idiot probably...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Apply the cleaning function to each tweet in the dataframe\n",
    "merged_df['cleaned_text'] = merged_df['text'].apply(clean_text)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "merged_df.to_csv('cleaned_tweets.csv', index=False)\n",
    "\n",
    "merged_df.dropna(subset=['cleaned_text'], inplace=True)\n",
    "\n",
    "# Display the cleaned and normalized text\n",
    "print(merged_df['cleaned_text'].head())\n",
    "print(merged_df['cleaned_text'].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a2a833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
